{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[3. 9.]\n"
     ]
    }
   ],
   "source": [
    "X = np.array(([2, 9], [1, 5], [3, 6]), dtype=float)\n",
    "print(np.amax(X, axis=0))\n",
    "y = np.array(([92], [86], [89]), dtype=float)\n",
    "\n",
    "\n",
    "X = X/np.amax(X, axis=0)\n",
    "y = y/100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network(object):\n",
    "    def __init__(self):\n",
    "        self.inputSize = 2\n",
    "        self.outputSize = 1\n",
    "        self.hiddenSize = 3\n",
    "\n",
    "        #weights\n",
    "        self.W1 = np.random.randn(self.inputSize, self.hiddenSize) # (3x2) weight matrix from input to hidden layer\n",
    "        self.W2 = np.random.randn(self.hiddenSize, self.outputSize) # (3x1) weight matrix from hidden to output layer\n",
    "\n",
    "    def forward(self, X):\n",
    "        #forward propagation through our network\n",
    "        self.z = np.dot(X, self.W1) # dot product of X (input) and first set of 3x2 weights\n",
    "        self.z2 = self.sigmoid(self.z) # activation function\n",
    "        self.z3 = np.dot(self.z2, self.W2) # dot product of hidden layer (z2) and second set of 3x1 weights\n",
    "        o = self.sigmoid(self.z3) # final activation function\n",
    "        return o \n",
    "\n",
    "    def sigmoid(self, s):\n",
    "        # activation function \n",
    "        return 1/(1+np.exp(-s))\n",
    "\n",
    "    def sigmoidPrime(self, s):\n",
    "        #derivative of sigmoid\n",
    "        return s * (1 - s)\n",
    "\n",
    "    def backward(self, X, y, o):\n",
    "        # backward propgate through the network\n",
    "        self.o_error = y - o # error in output\n",
    "        self.o_delta = self.o_error*self.sigmoidPrime(o) # applying derivative of sigmoid to error\n",
    "\n",
    "        self.z2_error = self.o_delta.dot(self.W2.T) # z2 error: how much our hidden layer weights contributed to output error\n",
    "        self.z2_delta = self.z2_error*self.sigmoidPrime(self.z2) # applying derivative of sigmoid to z2 error\n",
    "\n",
    "        self.W1 += l_rate*X.T.dot(self.z2_delta) # adjusting first set (input --> hidden) weights\n",
    "        self.W2 += l_rate*self.z2.T.dot(self.o_delta) # adjusting second set (hidden --> output) weights\n",
    "\n",
    "    def train (self, X, y):\n",
    "        o = self.forward(X)\n",
    "        self.backward(X, y, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0\nl_rate 0.1\nInput: \n [[0.66666667 1.        ]\n [0.33333333 0.55555556]\n [1.         0.66666667]]\nActual Output: \n [[0.92]\n [0.86]\n [0.89]]\nPredicted Output: \n [[0.58229267]\n [0.54229474]\n [0.58944813]]\nLoss: \n 0.10177143288864755\n\n\nEpoch: 1\nl_rate 0.1\nInput: \n [[0.66666667 1.        ]\n [0.33333333 0.55555556]\n [1.         0.66666667]]\nActual Output: \n [[0.92]\n [0.86]\n [0.89]]\nPredicted Output: \n [[0.58651014]\n [0.54636792]\n [0.59386856]]\nLoss: \n 0.09909146769716427\n\n\nEpoch: 2\nl_rate 0.1\nInput: \n [[0.66666667 1.        ]\n [0.33333333 0.55555556]\n [1.         0.66666667]]\nActual Output: \n [[0.92]\n [0.86]\n [0.89]]\nPredicted Output: \n [[0.59066197]\n [0.55037869]\n [0.59821715]]\nLoss: \n 0.09648870742358112\n\n\nEpoch: 3\nl_rate 0.1\nInput: \n [[0.66666667 1.        ]\n [0.33333333 0.55555556]\n [1.         0.66666667]]\nActual Output: \n [[0.92]\n [0.86]\n [0.89]]\nPredicted Output: \n [[0.59474871]\n [0.55432749]\n [0.60249453]]\nLoss: \n 0.09396115860953323\n\n\nEpoch: 4\nl_rate 0.1\nInput: \n [[0.66666667 1.        ]\n [0.33333333 0.55555556]\n [1.         0.66666667]]\nActual Output: \n [[0.92]\n [0.86]\n [0.89]]\nPredicted Output: \n [[0.59877094]\n [0.5582148 ]\n [0.60670135]]\nLoss: \n 0.09150684786946055\n\n\nEpoch: 5\nl_rate 0.1\nInput: \n [[0.66666667 1.        ]\n [0.33333333 0.55555556]\n [1.         0.66666667]]\nActual Output: \n [[0.92]\n [0.86]\n [0.89]]\nPredicted Output: \n [[0.60272926]\n [0.56204111]\n [0.6108383 ]]\nLoss: \n 0.08912382461977518\n\n\nEpoch: 6\nl_rate 0.1\nInput: \n [[0.66666667 1.        ]\n [0.33333333 0.55555556]\n [1.         0.66666667]]\nActual Output: \n [[0.92]\n [0.86]\n [0.89]]\nPredicted Output: \n [[0.60662433]\n [0.56580699]\n [0.61490611]]\nLoss: \n 0.08681016352042964\n\n\nEpoch: 7\nl_rate 0.1\nInput: \n [[0.66666667 1.        ]\n [0.33333333 0.55555556]\n [1.         0.66666667]]\nActual Output: \n [[0.92]\n [0.86]\n [0.89]]\nPredicted Output: \n [[0.6104568 ]\n [0.569513  ]\n [0.61890553]]\nLoss: \n 0.08456396664576478\n\n\nEpoch: 8\nl_rate 0.1\nInput: \n [[0.66666667 1.        ]\n [0.33333333 0.55555556]\n [1.         0.66666667]]\nActual Output: \n [[0.92]\n [0.86]\n [0.89]]\nPredicted Output: \n [[0.61422737]\n [0.57315978]\n [0.62283735]]\nLoss: \n 0.08238336540098083\n\n\nEpoch: 9\nl_rate 0.1\nInput: \n [[0.66666667 1.        ]\n [0.33333333 0.55555556]\n [1.         0.66666667]]\nActual Output: \n [[0.92]\n [0.86]\n [0.89]]\nPredicted Output: \n [[0.61793675]\n [0.57674796]\n [0.62670238]]\nLoss: \n 0.08026652220003712\n\n\nEpoch: 10\nl_rate 0.1\nInput: \n [[0.66666667 1.        ]\n [0.33333333 0.55555556]\n [1.         0.66666667]]\nActual Output: \n [[0.92]\n [0.86]\n [0.89]]\nPredicted Output: \n [[0.62158566]\n [0.58027821]\n [0.63050146]]\nLoss: \n 0.07821163192024079\n\n\nEpoch: 11\nl_rate 0.1\nInput: \n [[0.66666667 1.        ]\n [0.33333333 0.55555556]\n [1.         0.66666667]]\nActual Output: \n [[0.92]\n [0.86]\n [0.89]]\nPredicted Output: \n [[0.62517485]\n [0.58375121]\n [0.63423544]]\nLoss: \n 0.07621692314823615\n\n\nEpoch: 12\nl_rate 0.1\nInput: \n [[0.66666667 1.        ]\n [0.33333333 0.55555556]\n [1.         0.66666667]]\nActual Output: \n [[0.92]\n [0.86]\n [0.89]]\nPredicted Output: \n [[0.6287051 ]\n [0.58716768]\n [0.63790521]]\nLoss: \n 0.07428065923155806\n\n\nEpoch: 13\nl_rate 0.1\nInput: \n [[0.66666667 1.        ]\n [0.33333333 0.55555556]\n [1.         0.66666667]]\nActual Output: \n [[0.92]\n [0.86]\n [0.89]]\nPredicted Output: \n [[0.63217716]\n [0.59052835]\n [0.64151164]]\nLoss: \n 0.07240113914935835\n\n\nEpoch: 14\nl_rate 0.1\nInput: \n [[0.66666667 1.        ]\n [0.33333333 0.55555556]\n [1.         0.66666667]]\nActual Output: \n [[0.92]\n [0.86]\n [0.89]]\nPredicted Output: \n [[0.63559184]\n [0.59383397]\n [0.64505565]]\nLoss: \n 0.07057669821536482\n\n\nEpoch: 15\nl_rate 0.1\nInput: \n [[0.66666667 1.        ]\n [0.33333333 0.55555556]\n [1.         0.66666667]]\nActual Output: \n [[0.92]\n [0.86]\n [0.89]]\nPredicted Output: \n [[0.63894992]\n [0.59708527]\n [0.64853815]]\nLoss: \n 0.06880570862557864\n\n\nEpoch: 16\nl_rate 0.1\nInput: \n [[0.66666667 1.        ]\n [0.33333333 0.55555556]\n [1.         0.66666667]]\nActual Output: \n [[0.92]\n [0.86]\n [0.89]]\nPredicted Output: \n [[0.64225222]\n [0.60028305]\n [0.65196006]]\nLoss: \n 0.06708657986266771\n\n\nEpoch: 17\nl_rate 0.1\nInput: \n [[0.66666667 1.        ]\n [0.33333333 0.55555556]\n [1.         0.66666667]]\nActual Output: \n [[0.92]\n [0.86]\n [0.89]]\nPredicted Output: \n [[0.64549954]\n [0.60342806]\n [0.65532232]]\nLoss: \n 0.06541775896846515\n\n\nEpoch: 18\nl_rate 0.1\nInput: \n [[0.66666667 1.        ]\n [0.33333333 0.55555556]\n [1.         0.66666667]]\nActual Output: \n [[0.92]\n [0.86]\n [0.89]]\nPredicted Output: \n [[0.6486927 ]\n [0.6065211 ]\n [0.65862586]]\nLoss: \n 0.06379773069544016\n\n\nEpoch: 19\nl_rate 0.1\nInput: \n [[0.66666667 1.        ]\n [0.33333333 0.55555556]\n [1.         0.66666667]]\nActual Output: \n [[0.92]\n [0.86]\n [0.89]]\nPredicted Output: \n [[0.65183253]\n [0.60956296]\n [0.66187163]]\nLoss: \n 0.06222501754746962\n\n\nEpoch: 20\nl_rate 0.1\nInput: \n [[0.66666667 1.        ]\n [0.33333333 0.55555556]\n [1.         0.66666667]]\nActual Output: \n [[0.92]\n [0.86]\n [0.89]]\nPredicted Output: \n [[0.65491985]\n [0.61255443]\n [0.66506057]]\nLoss: \n 0.06069817971970829\n\n\nEpoch: 21\nl_rate 0.1\nInput: \n [[0.66666667 1.        ]\n [0.33333333 0.55555556]\n [1.         0.66666667]]\nActual Output: \n [[0.92]\n [0.86]\n [0.89]]\nPredicted Output: \n [[0.65795549]\n [0.61549632]\n [0.66819363]]\nLoss: \n 0.05921581494683218\n\n\nEpoch: 22\nl_rate 0.1\nInput: \n [[0.66666667 1.        ]\n [0.33333333 0.55555556]\n [1.         0.66666667]]\nActual Output: \n [[0.92]\n [0.86]\n [0.89]]\nPredicted Output: \n [[0.66094027]\n [0.61838941]\n [0.67127174]]\nLoss: \n 0.05777655826841429\n\n\nEpoch: 23\nl_rate 0.1\nInput: \n [[0.66666667 1.        ]\n [0.33333333 0.55555556]\n [1.         0.66666667]]\nActual Output: \n [[0.92]\n [0.86]\n [0.89]]\nPredicted Output: \n [[0.66387501]\n [0.62123451]\n [0.67429586]]\nLoss: \n 0.05637908171969059\n\n\nEpoch: 24\nl_rate 0.1\nInput: \n [[0.66666667 1.        ]\n [0.33333333 0.55555556]\n [1.         0.66666667]]\nActual Output: \n [[0.92]\n [0.86]\n [0.89]]\nPredicted Output: \n [[0.66676056]\n [0.62403242]\n [0.67726691]]\nLoss: \n 0.055022093955479655\n\n\nEpoch: 25\nl_rate 0.1\nInput: \n [[0.66666667 1.        ]\n [0.33333333 0.55555556]\n [1.         0.66666667]]\nActual Output: \n [[0.92]\n [0.86]\n [0.89]]\nPredicted Output: \n [[0.66959771]\n [0.62678393]\n [0.68018585]]\nLoss: \n 0.05370433981454211\n\n\nEpoch: 26\nl_rate 0.1\nInput: \n [[0.66666667 1.        ]\n [0.33333333 0.55555556]\n [1.         0.66666667]]\nActual Output: \n [[0.92]\n [0.86]\n [0.89]]\nPredicted Output: \n [[0.6723873 ]\n [0.62948984]\n [0.68305359]]\nLoss: \n 0.05242459983119999\n\n\nEpoch: 27\nl_rate 0.1\nInput: \n [[0.66666667 1.        ]\n [0.33333333 0.55555556]\n [1.         0.66666667]]\nActual Output: \n [[0.92]\n [0.86]\n [0.89]]\nPredicted Output: \n [[0.67513013]\n [0.63215093]\n [0.68587107]]\nLoss: \n 0.05118168970058536\n\n\nEpoch: 28\nl_rate 0.1\nInput: \n [[0.66666667 1.        ]\n [0.33333333 0.55555556]\n [1.         0.66666667]]\nActual Output: \n [[0.92]\n [0.86]\n [0.89]]\nPredicted Output: \n [[0.67782702]\n [0.634768  ]\n [0.68863919]]\nLoss: \n 0.04997445970345308\n\n\nEpoch: 29\nl_rate 0.1\nInput: \n [[0.66666667 1.        ]\n [0.33333333 0.55555556]\n [1.         0.66666667]]\nActual Output: \n [[0.92]\n [0.86]\n [0.89]]\nPredicted Output: \n [[0.68047877]\n [0.63734181]\n [0.69135888]]\nLoss: \n 0.04880179409607305\n\n\n"
     ]
    }
   ],
   "source": [
    "NN = Neural_Network()\n",
    "l_rate=0.1\n",
    "for i in range(30): # trains the NN 1,000 times\n",
    "    print(\"Epoch:\",i)\n",
    "    print(\"l_rate\",l_rate)\n",
    "    print (\"Input: \\n\",str(X))\n",
    "    print (\"Actual Output: \\n\",str(y) )\n",
    "    print (\"Predicted Output: \\n\",str(NN.forward(X)) )\n",
    "    print (\"Loss: \\n\",str(np.mean(np.square(y - NN.forward(X)))))\n",
    "    print (\"\\n\")\n",
    "    NN.train(X, y)"
   ]
  }
 ]
}